{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32973d7-b5f9-4e17-8daf-9dbc358f6b1d",
   "metadata": {},
   "source": [
    "# Stemming in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42600df1-2405-4071-8b65-a845ab170bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040278c5-36eb-412f-aaac-9340d558d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = ['change', 'changing', 'changes', 'changed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e14f3e-d7ba-4dd2-9734-2eefb7cc7d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change', 'changing', 'changes', 'changed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4458ba6f-709e-43b2-90ca-9abb4edd11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1554a6a3-3363-42f7-9226-a6eb0870f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43a8cfc-0728-4b1e-bb99-96dac1399571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PorterStemmer>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "174da1a7-de7f-4a02-a377-02ed3ccc19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem('change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64c12c6-1378-437c-b620-7e9e281e7a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chang\n",
      "chang\n",
      "chang\n",
      "chang\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(p.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a88093-80b4-45ec-a088-48b1205c322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change chang\n",
      "changing chang\n",
      "changes chang\n",
      "changed chang\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(w, p.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d918a59-d99c-4a2f-8611-57f80f552634",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = 'The constant flux of life necessitates embracing change, whether its adapting to the changes around us or actively changing ourselves to meet new challenges.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b91e22-fb63-4761-b132-3f60395c0514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The constant flux of life necessitates embracing change, whether its adapting to the changes around us or actively changing ourselves to meet new challenges.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071912e9-4dd7-48aa-b357-edb8d0609bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5861e088-0ddd-4dad-b889-c392e5395342",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = word_tokenize(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4920f553-15df-4841-be5a-31d5b0c60659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'constant',\n",
       " 'flux',\n",
       " 'of',\n",
       " 'life',\n",
       " 'necessitates',\n",
       " 'embracing',\n",
       " 'change',\n",
       " ',',\n",
       " 'whether',\n",
       " 'its',\n",
       " 'adapting',\n",
       " 'to',\n",
       " 'the',\n",
       " 'changes',\n",
       " 'around',\n",
       " 'us',\n",
       " 'or',\n",
       " 'actively',\n",
       " 'changing',\n",
       " 'ourselves',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'new',\n",
       " 'challenges',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "715d6108-cbae-472c-a5ae-82bb9a183b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eae153b-1c7c-41fc-ac2f-5502d93cc56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sen.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30d9fe6-8431-4262-8539-c9c4cb30069f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "constant\n",
      "flux\n",
      "of\n",
      "life\n",
      "necessit\n",
      "embrac\n",
      "chang\n",
      ",\n",
      "whether\n",
      "it\n",
      "adapt\n",
      "to\n",
      "the\n",
      "chang\n",
      "around\n",
      "us\n",
      "or\n",
      "activ\n",
      "chang\n",
      "ourselv\n",
      "to\n",
      "meet\n",
      "new\n",
      "challeng\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for w in token:\n",
    "    print(p.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28acf766-82b3-4ef6-9266-bd53d94a0b2e",
   "metadata": {},
   "source": [
    "# Lemmatization in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c5515a2-10d5-462d-9bc0-5a9c2770d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eab3998a-4cf2-4856-9919-d32e794f6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7438e24f-511e-43d3-ac42-54c1534a9f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordNetLemmatizer>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51803e8f-8c4c-4ff1-9e71-b7d08ad5c1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'constant',\n",
       " 'flux',\n",
       " 'of',\n",
       " 'life',\n",
       " 'necessitates',\n",
       " 'embracing',\n",
       " 'change',\n",
       " ',',\n",
       " 'whether',\n",
       " 'its',\n",
       " 'adapting',\n",
       " 'to',\n",
       " 'the',\n",
       " 'changes',\n",
       " 'around',\n",
       " 'us',\n",
       " 'or',\n",
       " 'actively',\n",
       " 'changing',\n",
       " 'ourselves',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'new',\n",
       " 'challenges',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "422524f0-a0dc-4c77-963b-54e571bdc55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "constant\n",
      "flux\n",
      "of\n",
      "life\n",
      "necessitates\n",
      "embracing\n",
      "change\n",
      ",\n",
      "whether\n",
      "it\n",
      "adapting\n",
      "to\n",
      "the\n",
      "change\n",
      "around\n",
      "u\n",
      "or\n",
      "actively\n",
      "changing\n",
      "ourselves\n",
      "to\n",
      "meet\n",
      "new\n",
      "challenge\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for w in token:\n",
    "    print(le.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ef9ef3c-bd79-4c26-b671-66eae64169f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'changing'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.lemmatize('changing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d239a030-4ed8-4889-b7d9-d979dfec7df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change', 'changing', 'changes', 'changed']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96a19fe3-c312-4599-a5c8-53c29e189c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "change\n",
      "changing\n",
      "change\n",
      "changed\n"
     ]
    }
   ],
   "source": [
    "for w in word:\n",
    "    print(le.lemmatize(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5c1ed-9033-4887-8865-2b03778f6097",
   "metadata": {},
   "source": [
    "# Tokenization in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb666a0b-8f3a-4522-bd2e-d63ea930513f",
   "metadata": {},
   "source": [
    "In python there are several libraries and tools available for performing tokenization and other NLP tasks. Here are few examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20808d8-32d9-484f-9964-79f72ca36e4e",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812b4e9-036b-4d11-b1ea-1b628af49e10",
   "metadata": {},
   "source": [
    "NLTK ( Natural Language Tool kit) is a widely used library for NLP tasks. To perform tokenization using NLTK, you need to install it first. You can do so by running pip install nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d215610-0131-4831-9406-cac1845e99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "903fcb0c-0cd4-4c75-ab7b-2f28ab66250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm from aiQuest Intelligence. I live in germany. I am learning NLP. It is fascinating!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80edc6fd-a64b-4857-b534-f36aa81a7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = word_tokenize(sentence)\n",
    "sentence_token = sent_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59b9b49d-6c9e-45f6-8fee-4762c8604143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'from', 'aiQuest', 'Intelligence', '.', 'I', 'live', 'in', 'germany', '.', 'I', 'am', 'learning', 'NLP', '.', 'It', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "print(word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "076a2a46-5d5b-4adc-91cd-4c6c206508b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm from aiQuest Intelligence.\", 'I live in germany.', 'I am learning NLP.', 'It is fascinating!']\n"
     ]
    }
   ],
   "source": [
    "print(sentence_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66768823-11d0-467d-8f51-552501f626b6",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2faca2-bacf-4821-b86d-1e24ad64cc09",
   "metadata": {},
   "source": [
    "Spacy is another powerful library for NLP. To install spaCy you need to install pip install spacy and then download the appropriate language model. Here is an example of tokenization using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e7ce972-1f1a-4c48-bc24-ddba904c4ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aefc7c4-2590-462b-84a4-12349700823d",
   "metadata": {},
   "source": [
    "## Load the English Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51e5f591-5e1b-4d0c-ae1a-2ac5b55cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spc = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb227b4d-fd53-4682-9a65-f6ac7d891cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x24724523390>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "341a7abb-98db-429d-ba5b-2c4243b0d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm from aiQuest Intelligence. I live in germany. I am learning NLP. It is fascinating!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "241a04ef-1040-4da6-985d-33338dada4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spc(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2eee7f35-423d-4bb9-b93b-27ea0cbc4091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I'm from aiQuest Intelligence. I live in germany. I am learning NLP. It is fascinating!"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a1aad8e-0283-4914-bfb4-090e33aba11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d91f474c-5601-4488-9fed-a502dc5c629d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'m\",\n",
       " 'from',\n",
       " 'aiQuest',\n",
       " 'Intelligence',\n",
       " '.',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'germany',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'NLP',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'fascinating',\n",
       " '!']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656237fd-e786-4295-9cd7-d2f0821debe4",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac56966-c6e0-4e79-b3ec-06ee75bd2fee",
   "metadata": {},
   "source": [
    "Transformer is a library  built by Hugging face that provides state-of-the-art pre-trained model for NLP. It offers various functionalities \n",
    "including tokenization. To install transformers, run pip install transformers. Here is an example of\n",
    "tokenization using transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8ffc11a-91c8-4c14-964a-0203e77f0413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c04f92f4-41ce-4028-b4ba-9db70b54684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2622b6a-c477-4e13-ad81-df7a0714c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm from aiQuest Intelligence. I am learning NLP. It is fascinating!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c88e4612-2b84-4def-974a-feb9fa107084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'from', 'ai', '##quest', 'intelligence', '.', 'i', 'am', 'learning', 'nl', '##p', '.', 'it', 'is', 'fascinating', '!']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e6511-0538-4e11-ab53-595abe9c17aa",
   "metadata": {},
   "source": [
    "# Named Entity Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab58b7eb-849b-4277-956c-21f6abc3d691",
   "metadata": {},
   "source": [
    "To perform named entity tokenization using NLTK, you can utilize named entity recognition(NER) functionality provided by NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "826aeeb2-7f31-4d7b-bc23-7dc071cab427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x*2 for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c8e48f3-dae9-4535-976a-35c7f263753d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([x*2 for x in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "699e2d03-5ada-4792-aa53-04d847c78503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 4, 6, 8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([x*2 for x in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab7170c-9753-414a-9865-69e3d7534b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof([x*2 for x in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae3a1411-a77b-4a19-a2b6-fce267691081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(tuple([x*2 for x in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35a15254-e8f0-4454-948a-b65c75739c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc730521-70b0-4ecc-9d97-c9bd6bd843db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm from aiQuest Intelligence. I live in Germany. I am learning NLP. It is fascinating!, Hasan khan, my name is Joe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3a4cf6a-37cb-4f88-9a77-064c53ef0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sentence) # Tokenize the sentence into words\n",
    "pos_tags = pos_tag(tokens) # Perform parts of speech tagging\n",
    "ner_tag = ne_chunk(pos_tags) # Perform Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04ad4af2-80b1-4454-aad2-688d0e5733ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiQuest Intelligence', 'Germany', 'NLP', 'Hasan', 'Joe']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entity_tokens = []\n",
    "for chunk in ner_tag:\n",
    "    if hasattr(chunk, 'label'):\n",
    "        named_entity_tokens.append(' '.join(c[0] for c in chunk))\n",
    "named_entity_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ada8226-f71a-4d61-9810-e5c083173ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"Shakil lives in Germany\"\n",
    "token = word_tokenize(sentence2)\n",
    "pos_tag = pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c169ba6-49c3-416c-84bf-e178fb4b2aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Shakil', 'NNP'), ('lives', 'VBZ'), ('in', 'IN'), ('Germany', 'NNP')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195fad7-a4b6-40cd-b147-23d025d72726",
   "metadata": {},
   "source": [
    "# Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78c1b50a-162c-4646-8adc-e8b6396ae382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"D:/DL_ML_AiQuest_PacticeWork/class_practice_project/Datasets/data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3b365d6e-9fd2-49d1-8652-4d95db5b9d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey, I love Bangladesh;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon, I am happy!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I live in Germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice to meet you man-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You won an iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text  class\n",
       "0      Hey, I love Bangladesh;      1\n",
       "1  Good afternoon, I am happy!      1\n",
       "2            I live in Germany      1\n",
       "3        Nice to meet you man-      1\n",
       "4            You won an iPhone      0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6b51e-0747-4332-a251-2c9d2c29cecf",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b6bb66ea-5887-4bcd-b606-d1240a7bfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87d857da-2443-4fbe-a3ec-6874e1805b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02aeea44-ac41-4977-87fd-ede76820db8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'through', \"wasn't\", 'into', 'ourselves', 'which', 'we', 'haven', 'than', 'ma', 'has', 'same', 'above', 'over', \"won't\", 'my', 'only', 'so', 'isn', 'i', 'hers', \"hasn't\", 'wouldn', 'mustn', \"aren't\", 'all', 'have', 'myself', 'very', 'wasn', 'about', 'no', 'nor', 'him', 'here', 'for', 'that', 'is', 'they', 'these', 'do', 'to', 'itself', 'this', 'having', 'again', \"you've\", 'once', 'yours', 're', 'there', \"shan't\", 'such', \"don't\", 'too', 'are', 'm', \"you're\", 'yourself', 'more', 'did', 'were', 'her', \"mustn't\", 'against', 'any', \"should've\", 'how', 'been', 'what', 'aren', 'y', 'theirs', 'doesn', 'each', 'hasn', \"she's\", 'now', 'had', 'won', 'of', \"needn't\", 'own', 'while', 'whom', 'other', 'those', \"mightn't\", 'the', 'should', 'herself', 'he', 'or', 'needn', 'as', 'their', 'before', 'shan', 'doing', 'she', 'mightn', \"you'll\", 'hadn', 'between', \"you'd\", 'both', 'down', 'will', 'yourselves', 'was', 'on', 'few', 'am', \"couldn't\", 'ain', 'just', \"haven't\", 'our', 'shouldn', 'didn', \"doesn't\", 'under', 'it', 'further', \"isn't\", 'your', 'off', \"weren't\", 'from', \"it's\", 'you', 've', 'not', 's', 'its', 'and', 'at', 'them', 'me', 'being', 'in', 'be', 'when', 'where', \"hadn't\", 'if', 'then', 'ours', 'up', 'some', 'his', 'after', 'because', 'does', 'll', 't', 'below', \"shouldn't\", 'couldn', 'but', 'until', 'o', \"wouldn't\", 'themselves', 'with', 'don', 'himself', 'weren', \"that'll\", 'during', 'why', 'out', \"didn't\", 'most', 'can', 'd', 'an', 'by', 'a', 'who'}\n"
     ]
    }
   ],
   "source": [
    "print(en_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e23b8b45-825e-4309-8590-e04d530e26c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c14edefb-6593-4c9c-ac95-8a6e172cb289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['অতএব', 'অথচ', 'অথবা', 'অনুযায়ী', 'অনেক', 'অনেকে', 'অনেকেই', 'অন্তত', 'অন্য', 'অবধি', 'অবশ্য', 'অর্থাত', 'আই', 'আগামী', 'আগে', 'আগেই', 'আছে', 'আজ', 'আদ্যভাগে', 'আপনার', 'আপনি', 'আবার', 'আমরা', 'আমাকে', 'আমাদের', 'আমার', 'আমি', 'আর', 'আরও', 'ই', 'ইত্যাদি', 'ইহা', 'উচিত', 'উত্তর', 'উনি', 'উপর', 'উপরে', 'এ', 'এঁদের', 'এঁরা', 'এই', 'একই', 'একটি', 'একবার', 'একে', 'এক্', 'এখন', 'এখনও', 'এখানে', 'এখানেই', 'এটা', 'এটাই', 'এটি', 'এত', 'এতটাই', 'এতে', 'এদের', 'এব', 'এবং', 'এবার', 'এমন', 'এমনকী', 'এমনি', 'এর', 'এরা', 'এল', 'এস', 'এসে', 'ঐ', 'ও', 'ওঁদের', 'ওঁর', 'ওঁরা', 'ওই', 'ওকে', 'ওখানে', 'ওদের', 'ওর', 'ওরা', 'কখনও', 'কত', 'কবে', 'কমনে', 'কয়েক', 'কয়েকটি', 'করছে', 'করছেন', 'করতে', 'করবে', 'করবেন', 'করলে', 'করলেন', 'করা', 'করাই', 'করায়', 'করার', 'করি', 'করিতে', 'করিয়া', 'করিয়ে', 'করে', 'করেই', 'করেছিলেন', 'করেছে', 'করেছেন', 'করেন', 'কাউকে', 'কাছ', 'কাছে', 'কাজ', 'কাজে', 'কারও', 'কারণ', 'কি', 'কিংবা', 'কিছু', 'কিছুই', 'কিন্তু', 'কী', 'কে', 'কেউ', 'কেউই', 'কেখা', 'কেন', 'কোটি', 'কোন', 'কোনও', 'কোনো', 'ক্ষেত্রে', 'কয়েক', 'খুব', 'গিয়ে', 'গিয়েছে', 'গিয়ে', 'গুলি', 'গেছে', 'গেল', 'গেলে', 'গোটা', 'চলে', 'চান', 'চায়', 'চার', 'চালু', 'চেয়ে', 'চেষ্টা', 'ছাড়া', 'ছাড়াও', 'ছিল', 'ছিলেন', 'জন', 'জনকে', 'জনের', 'জন্য', 'জন্যওজে', 'জানতে', 'জানা', 'জানানো', 'জানায়', 'জানিয়ে', 'জানিয়েছে', 'জে', 'জ্নজন', 'টি', 'ঠিক', 'তখন', 'তত', 'তথা', 'তবু', 'তবে', 'তা', 'তাঁকে', 'তাঁদের', 'তাঁর', 'তাঁরা', 'তাঁাহারা', 'তাই', 'তাও', 'তাকে', 'তাতে', 'তাদের', 'তার', 'তারপর', 'তারা', 'তারৈ', 'তাহলে', 'তাহা', 'তাহাতে', 'তাহার', 'তিনঐ', 'তিনি', 'তিনিও', 'তুমি', 'তুলে', 'তেমন', 'তো', 'তোমার', 'থাকবে', 'থাকবেন', 'থাকা', 'থাকায়', 'থাকে', 'থাকেন', 'থেকে', 'থেকেই', 'থেকেও', 'দিকে', 'দিতে', 'দিন', 'দিয়ে', 'দিয়েছে', 'দিয়েছেন', 'দিলেন', 'দু', 'দুই', 'দুটি', 'দুটো', 'দেওয়া', 'দেওয়ার', 'দেওয়া', 'দেখতে', 'দেখা', 'দেখে', 'দেন', 'দেয়', 'দ্বারা', 'ধরা', 'ধরে', 'ধামার', 'নতুন', 'নয়', 'না', 'নাই', 'নাকি', 'নাগাদ', 'নানা', 'নিজে', 'নিজেই', 'নিজেদের', 'নিজের', 'নিতে', 'নিয়ে', 'নিয়ে', 'নেই', 'নেওয়া', 'নেওয়ার', 'নেওয়া', 'নয়', 'পক্ষে', 'পর', 'পরে', 'পরেই', 'পরেও', 'পর্যন্ত', 'পাওয়া', 'পাচ', 'পারি', 'পারে', 'পারেন', 'পি', 'পেয়ে', 'পেয়্র্', 'প্রতি', 'প্রথম', 'প্রভৃতি', 'প্রযন্ত', 'প্রাথমিক', 'প্রায়', 'প্রায়', 'ফলে', 'ফিরে', 'ফের', 'বক্তব্য', 'বদলে', 'বন', 'বরং', 'বলতে', 'বলল', 'বললেন', 'বলা', 'বলে', 'বলেছেন', 'বলেন', 'বসে', 'বহু', 'বা', 'বাদে', 'বার', 'বি', 'বিনা', 'বিভিন্ন', 'বিশেষ', 'বিষয়টি', 'বেশ', 'বেশি', 'ব্যবহার', 'ব্যাপারে', 'ভাবে', 'ভাবেই', 'মতো', 'মতোই', 'মধ্যভাগে', 'মধ্যে', 'মধ্যেই', 'মধ্যেও', 'মনে', 'মাত্র', 'মাধ্যমে', 'মোট', 'মোটেই', 'যখন', 'যত', 'যতটা', 'যথেষ্ট', 'যদি', 'যদিও', 'যা', 'যাঁর', 'যাঁরা', 'যাওয়া', 'যাওয়ার', 'যাওয়া', 'যাকে', 'যাচ্ছে', 'যাতে', 'যাদের', 'যান', 'যাবে', 'যায়', 'যার', 'যারা', 'যিনি', 'যে', 'যেখানে', 'যেতে', 'যেন', 'যেমন', 'র', 'রকম', 'রয়েছে', 'রাখা', 'রেখে', 'লক্ষ', 'শুধু', 'শুরু', 'সঙ্গে', 'সঙ্গেও', 'সব', 'সবার', 'সমস্ত', 'সম্প্রতি', 'সহ', 'সহিত', 'সাধারণ', 'সামনে', 'সি', 'সুতরাং', 'সে', 'সেই', 'সেখান', 'সেখানে', 'সেটা', 'সেটাই', 'সেটাও', 'সেটি', 'স্পষ্ট', 'স্বয়ং', 'হইতে', 'হইবে', 'হইয়া', 'হওয়া', 'হওয়ায়', 'হওয়ার', 'হচ্ছে', 'হত', 'হতে', 'হতেই', 'হন', 'হবে', 'হবেন', 'হয়', 'হয়তো', 'হয়নি', 'হয়ে', 'হয়েই', 'হয়েছিল', 'হয়েছে', 'হয়েছেন', 'হল', 'হলে', 'হলেই', 'হলেও', 'হলো', 'হাজার', 'হিসাবে', 'হৈলে', 'হোক', 'হয়']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('bengali'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "057c19b7-1010-4607-9bcd-3124d18609fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21998036-865f-4236-a4a6-5b87b89eec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b93f2816-50a1-41bc-9007-b5324f3edc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shakil'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sHakIl'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5da520d3-f92f-41b1-a46a-c45648db0680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 54]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = [1, 2, 3, 4, 54]\n",
    "[l for l in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d4a5281-e9fe-4243-bffb-2b14b84f370c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l for l in li if l%2 !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5e0e755-334a-4a53-a1ee-a4750bf50b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey, I love Bangladesh;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good afternoon, I am happy!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I live in Germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nice to meet you man-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You won an iPhone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          text  class\n",
       "0      Hey, I love Bangladesh;      1\n",
       "1  Good afternoon, I am happy!      1\n",
       "2            I live in Germany      1\n",
       "3        Nice to meet you man-      1\n",
       "4            You won an iPhone      0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2780011-46ef-4ad4-b01b-49b5bd672f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 6]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x*2 for x in range(5) if x % 3 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02d4a760-78b7-495b-8c27-6eec8eec9dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2de74102-0a5c-4ead-b7f3-0bd4d47fba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    remove_punc = [char for char in text if char not in string.punctuation]\n",
    "    clean_words = ''.join(remove_punc)\n",
    "    split_words = clean_words.split()\n",
    "    text = [word for word in split_words if word.lower() not in stopwords.words('english')]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb943874-ebbc-497a-af99-d4b1b51f0c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Hey, love, Bangladesh]\n",
       "1    [Good, afternoon, happy]\n",
       "2             [live, Germany]\n",
       "3           [Nice, meet, man]\n",
       "4                    [iPhone]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9530a491-0d44-46ae-8037-60f4806b0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatized_text = ''.join([lemmatizer.lemmatize(word) for word in text])\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b891f6f-965c-4a55-b51c-2c6afc2b4e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     HeyloveBangladesh\n",
       "1    Goodafternoonhappy\n",
       "2           liveGermany\n",
       "3           Nicemeetman\n",
       "4                iPhone\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546289a-4781-46bf-bf34-38802a62e637",
   "metadata": {},
   "source": [
    "# Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f11d5330-b5c5-486f-8e49-f0124d75291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b60ecbe3-b69a-4df8-814f-a64d8ba9aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0ed7fae-1158-41f2-b5c1-791c4c51a39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "136b50df-9bf9-4466-b3c6-00b51e1c01ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x = cv.fit_transform(df['text'])\n",
    "cv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6100c2d-1c9a-48b0-aa7c-cb2bb0a3a70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4a1703f-677f-4216-ba40-47ccde0df420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  0  1  0  0  0\n",
       "1  1  0  0  0  0\n",
       "2  0  0  0  1  0\n",
       "3  0  0  0  0  1\n",
       "4  0  0  1  0  0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_x.toarray())\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba336aac-218c-4685-83d8-9db68fb2ecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['goodafternoonhappy', 'heylovebangladesh', 'iphone', 'livegermany',\n",
       "       'nicemeetman'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b3b3e40e-9a1b-436b-9c41-7ba9e897622f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodafternoonhappy</th>\n",
       "      <th>heylovebangladesh</th>\n",
       "      <th>iphone</th>\n",
       "      <th>livegermany</th>\n",
       "      <th>nicemeetman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HeyloveBangladesh</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goodafternoonhappy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveGermany</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicemeetman</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    goodafternoonhappy  heylovebangladesh  iphone  \\\n",
       "text                                                                \n",
       "HeyloveBangladesh                    0                  1       0   \n",
       "Goodafternoonhappy                   1                  0       0   \n",
       "liveGermany                          0                  0       0   \n",
       "Nicemeetman                          0                  0       0   \n",
       "iPhone                               0                  0       1   \n",
       "\n",
       "                    livegermany  nicemeetman  \n",
       "text                                          \n",
       "HeyloveBangladesh             0            0  \n",
       "Goodafternoonhappy            0            0  \n",
       "liveGermany                   1            0  \n",
       "Nicemeetman                   0            1  \n",
       "iPhone                        0            0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(cv_x.toarray(), index=df['text'], columns=cv.get_feature_names_out())\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a301426c-c152-4ebd-88b4-4dc568478b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = TfidfVectorizer()\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11ead953-5182-4d49-b791-bd4e8cac641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_z = tf.fit_transform(df['text'])\n",
    "tf_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7f7c8fcf-a021-43d6-b1e8-f192a0bcf203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goodafternoonhappy</th>\n",
       "      <th>heylovebangladesh</th>\n",
       "      <th>iphone</th>\n",
       "      <th>livegermany</th>\n",
       "      <th>nicemeetman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HeyloveBangladesh</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goodafternoonhappy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liveGermany</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicemeetman</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iPhone</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    goodafternoonhappy  heylovebangladesh  iphone  \\\n",
       "text                                                                \n",
       "HeyloveBangladesh                  0.0                1.0     0.0   \n",
       "Goodafternoonhappy                 1.0                0.0     0.0   \n",
       "liveGermany                        0.0                0.0     0.0   \n",
       "Nicemeetman                        0.0                0.0     0.0   \n",
       "iPhone                             0.0                0.0     1.0   \n",
       "\n",
       "                    livegermany  nicemeetman  \n",
       "text                                          \n",
       "HeyloveBangladesh           0.0          0.0  \n",
       "Goodafternoonhappy          0.0          0.0  \n",
       "liveGermany                 1.0          0.0  \n",
       "Nicemeetman                 0.0          1.0  \n",
       "iPhone                      0.0          0.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_tf = pd.DataFrame(tf_z.toarray(), index=df['text'], columns=tf.get_feature_names_out())\n",
    "cv_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f50c9-4424-4c41-8e3e-65432c2be3ed",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8ade9cdb-50aa-4ca0-b79f-e2397added44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c23a4155-ec55-4e53-a90d-c6567c0847a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['HeyloveBangladesh'],\n",
       " ['Goodafternoonhappy'],\n",
       " ['liveGermany'],\n",
       " ['Nicemeetman'],\n",
       " ['iPhone']]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector = [nltk.word_tokenize(test) for test in df['text']]\n",
    "text_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dfd79d5b-9f73-4543-b46c-d9b200f1324b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2473b90ef50>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Word2Vec(text_vector, min_count=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0d5c3809-275f-4725-8d6b-093712abe0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HeyloveBangladesh', 0.17018887400627136),\n",
       " ('Goodafternoonhappy', -0.013514947146177292),\n",
       " ('Nicemeetman', -0.023671656847000122),\n",
       " ('iPhone', -0.05234673246741295)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('liveGermany')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d96440-bf35-4dbc-8133-7c1d675775e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
